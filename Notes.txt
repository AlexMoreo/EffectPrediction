We have started trying to quantify each subreddit in a LOO manner.
The classifier does not see to be an accurate one.
It seems that if the type of shift is covariate shift (sophisticated quantifiers methods --PACC, EMQ---  work badly).
Per-period analysis does not seem to work.
3 class or 5 classes, not much difference.
Error measure: NMD (ordinal)
Jan 2025: In the new setup, we are keeping all common instances from the test set that have participated in any subreddit of the
training set as labelled instances. The task thus consists of predicting the prevalence of the "remainder" and then
combine with the prevalence of the common part. The common part can be exploited not to concur in training the
classifier but in calibrating it (e.g., for PCC) or to learn a correction method (for quantifiers). None of these seem
to work well.
13 Feb 2025: We have decided to switch to an experiment in which the training set and the test set is a stratified
partition of the whole, using the subreddits for stratification. The idea is to increasingly transfer instances from
the test set (initially bigger) to the training set (initially smaller) and measure performance.
This has suggested a connection with active learning, TAR for content moderation, and quantification...
We are also trying to predict period, using the scores of the periods before t as additional covariates to
predict for period t.

We maybe can endow PCC predictions with confidence intervals (see Denham et al. 2021)

TODO:
- Stratified
- Periods with history
- Recheck classifier accuracy, and Block-PCC: the blockwise typically works slightly better in accuracy and equal or
    slightly worse in macro F1
